# Auxiliary Gene Learning ğŸ§¬
"Auxiliary Gene Learning: Spatial Gene Expression Estimation by Auxiliary Gene Selection", in **AAAI2026** ğŸ‰ğŸ‰!

Shikui Kaito, Kazuya Nishimura, Shinnosuke Matsuo, Yasuhiro Kojima, Ryoma Bise

![Alt Text](./Overview_AGL.png)



## ğŸ“‘Abstract
*Developing neural network models to estimate spatial gene expression from pathological images is important for overcoming the high observational costs associated with spatial gene expression data.
In prior studies, only a small subset of highly variable genes has been used for expression estimation, despite tens of thousands of genes being observed, in order to enable evaluation that mitigates the impact of observational noise. Genes outside this subset have been excluded from the training process as well. However, since there are likely co-expression relationships between genes, low-expression genes may still contribute to the estimation of the evaluation target.
In this paper, we propose **Auxiliary Gene Learning** (AGL) that utilizes the benefit of the ignored genes by reformulating their expression estimation as auxiliary tasks and training them jointly with the primary tasks. To effectively leverage auxiliary genes, we must select a subset of auxiliary genes that positively influence the prediction of the evaluation genes.
However, this is a challenging optimization problem due to the vast number of possible combinations.
To overcome this challenge, we propose **Prior-Knowledge-Based Differentiable Top-$k$ Gene Selection via Bi-level Optimization** (DkGSB), a method that ranks genes by leveraging prior knowledge and relaxes the combinatorial selection problem into a differentiable top-$k$ selection problem.
The experiments demonstrate the effectiveness of incorporating auxiliary genes into the learning process and show that the proposed method outperforms conventional auxiliary task learning approaches.
*

## â¬‡ï¸ Installation
To set up their environment, please run:  
(we recommend to use [Anaconda](https://www.anaconda.com/) for installation.)
```
conda env create -n hest -f hest.yml
conda activate hest
```

## ğŸŒ Data Preparation
You can download and preprocess the required datasets from Hest-1K using the following commands.
```
python ./script/preprocess/load_hest1k.py
python ./script/preprocess/preprocess_hest1k.py
```

Split the data into 5-fold cross-validation.
```
python ./script/preprocess/split_to_5-fold_cv.py
```

## ğŸš€ Training the DkGSB
You can train our proposed **Prior-Knowledge-Based Differentiable Top-$k$ Gene Selection via Bi-level Optimization** (DkGSB) using the following command.
```
python ./script/main.py --module "AGL+DkGSB" --dataset 'TENX152'
```

## ğŸ”¥ Comparative Experiments
If you would like to run the comparative experiments, please execute the following commands:

1. **AGL** â€” Training with **all auxiliary genes**
```
python ./script/main.py --module "AGL" --dataset 'TENX152'
```
2. **Primary-only** â€” Training with **only the primary genes**
```
python ./script/main.py --module "PGL" --dataset 'TENX152'
```

## ğŸ” Citation
If you find this repository helpful, please consider citing:
```
Comming soon !
```

# âœï¸ Author
@ Shiku Kaito  
ãƒ» Contact: kaito.shiku@human.ait.kyushu-u.ac.jp
